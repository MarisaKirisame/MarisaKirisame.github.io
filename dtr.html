---
layout: default
title: Dynamic Tensor Rematerialization
---

<a href="https://arxiv.org/abs/2006.09616">Dynamic Tensor Rematerialization</a><br>

Gradient Checkpointing is a technique to save memory for Deep Neural Network training, or more generally, for reverse-mode automatic differentiation. <br>

As memory planning is NP-complete, and as gradient checkpointing has to memory plan for arbitary program with control flow, previous work made different restriction which sacrifice performance or usability. <br>

Some work assume the program exhibit a strict forward-backward data dependency pattern, and suffer performance degradtion for other data dependency pattern (for example, NN with highway connection/branching). <br>

Other work try to tackle the whole problem by using an ILP solver, which use lots of time to find the optimal memory planning, and can only be used for program without control flow, which pose problem for their application into real world deep learning framework, which often contain complex control flow. <br>

Additionally, gradient checkpointing couple the concept of calculating derivatives, with that of saving memory by recomputing, which add complexity and limit applications range. <br>

DTR tackle the above problems by planning the memory greedily at runtime, with a Tensor-Level Cache, instead of as a compiler pass. <br>

Adoption:<br>
<a href="https://github.com/MegEngine/MegEngine/wiki/Reduce-GPU-memory-usage-by-Dynamic-Tensor-Rematerialization">MegEngine</a><br>
